# app/services/naver_ranking_service.py
from __future__ import annotations

from typing import List, Optional, Set
from urllib.parse import urljoin, urlparse, parse_qs

import requests
from bs4 import BeautifulSoup

from app.schemas.naver_ranking import NaverRankingNewsItem
from app.db.postgres import save_naver_ranking_news
from app.services.llm_service import categorize_news_titles_by_gpt

# ë„¤ì´ë²„ ë­í‚¹ë‰´ìŠ¤(ë§ì´ ë³¸ ë‰´ìŠ¤) í˜ì´ì§€
NAVER_RANKING_URL = "https://news.naver.com/main/ranking/popularDay.naver"

# ë„¤ì´ë²„ ë‰´ìŠ¤ ì„¹ì…˜ ì½”ë“œ â†’ ì¹´í…Œê³ ë¦¬ëª… ë§¤í•‘ (ê¸°ì‚¬ ê°œë³„ ë§í¬ì— sid/sid1ê°€ ìˆì„ ë•Œë§Œ ì‚¬ìš© ê°€ëŠ¥)
SID_CATEGORY_MAP = {
    "100": "ì •ì¹˜",
    "101": "ê²½ì œ",
    "102": "ì‚¬íšŒ",
    "103": "ìƒí™œ/ë¬¸í™”",
    "104": "ì„¸ê³„",
    "105": "IT/ê³¼í•™",
    "110": "ì˜¤í”¼ë‹ˆì–¸",
}


def _extract_category_from_link(link: str) -> Optional[str]:
    """
    ê¸°ì‚¬ ë§í¬ì˜ ì¿¼ë¦¬ìŠ¤íŠ¸ë§(sid, sid1 ë“±)ì„ ë³´ê³  ì„¹ì…˜ ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ì¶œí•˜ëŠ” í—¬í¼.
    ì‹¤ì œ ë­í‚¹ í˜ì´ì§€ì˜ ê¸°ì‚¬ URLì€ ë³´í†µ sid íŒŒë¼ë¯¸í„°ê°€ ì—†ì–´ì„œ ëŒ€ë¶€ë¶„ Noneì¼ ê²ƒ.
    """
    try:
        parsed = urlparse(link)
        q = parse_qs(parsed.query)
        sid = q.get("sid1", [""])[0] or q.get("sid", [""])[0]
        if not sid:
            return None
        return SID_CATEGORY_MAP.get(sid)
    except Exception:
        return None


def fetch_naver_ranking_html(timeout: tuple[float, float] = (5.0, 20.0)) -> str:
    """
    ë„¤ì´ë²„ ë­í‚¹ë‰´ìŠ¤ HTMLì„ ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜.
    """
    headers = {
        "User-Agent": "Mozilla/5.0 (compatible; PostFlowBot/1.0; +https://example.com)"
    }
    resp = requests.get(NAVER_RANKING_URL, headers=headers, timeout=timeout)
    resp.raise_for_status()
    return resp.text


def parse_naver_ranking(html: str) -> List[NaverRankingNewsItem]:
    """
    ë„¤ì´ë²„ 'ì–¸ë¡ ì‚¬ë³„ ë­í‚¹ë‰´ìŠ¤' í˜ì´ì§€ HTMLì„ íŒŒì‹±í•´ì„œ
    (ì–¸ë¡ ì‚¬, ìˆœìœ„, ì œëª©, ë§í¬, ì¹´í…Œê³ ë¦¬) ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜.
    - ì–¸ë¡ ì‚¬: strong.rankingnews_name
    - ì œëª©: a.list_title
    - ë§í¬: a.list_title ì˜ href
    - ìˆœìœ„: em.list_ranking_num
    - ì¹´í…Œê³ ë¦¬: ë§í¬ì˜ sid/sid1 ê¸°ë°˜ ì¶”ì • (ì—†ìœ¼ë©´ None)
    """
    soup = BeautifulSoup(html, "lxml")
    items: List[NaverRankingNewsItem] = []

    # ì–¸ë¡ ì‚¬ë³„ ë¸”ë¡
    for box in soup.select("div.rankingnews_box"):
        press_el = box.select_one(".rankingnews_name")
        if not press_el:
            continue

        press_name = press_el.get_text(strip=True)

        # ì–¸ë¡ ì‚¬ë³„ ë­í‚¹ ë¦¬ìŠ¤íŠ¸ (ul.rankingnews_list > li)
        for li in box.select("ul.rankingnews_list > li"):
            # ìˆœìœ„
            rank_el = li.select_one("em.list_ranking_num")
            a_title = li.select_one("a.list_title")
            if not a_title:
                continue

            title = a_title.get_text(strip=True)
            href = a_title.get("href")
            if not title or not href:
                continue

            link = urljoin(NAVER_RANKING_URL, href)

            try:
                rank = int(rank_el.get_text(strip=True)) if rank_el else None
            except Exception:
                rank = None
            if rank is None:
                continue

            # ì¹´í…Œê³ ë¦¬: ê¸°ì‚¬ ë§í¬ì—ì„œ sid/sid1 ì¶”ì¶œ ì‹œë„ (ì—†ìœ¼ë©´ None)
            category = _extract_category_from_link(link)

            items.append(
                NaverRankingNewsItem(
                    press=press_name,
                    category=category,
                    rank=rank,
                    title=title,
                    link=link,
                )
            )

    return items


def _dedup_by_title(items: List[NaverRankingNewsItem]) -> List[NaverRankingNewsItem]:
    """
    ì œëª© ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±° (ê°™ì€ ì œëª©ì€ í•œ ë²ˆë§Œ ë‚¨ê¹€).
    """
    seen: Set[str] = set()
    deduped: List[NaverRankingNewsItem] = []

    for it in items:
        # ì™„ì „ ë™ì¼í•œ ë¬¸ìì—´ ê¸°ì¤€ (í•„ìš”í•˜ë©´ lower() ë“± ì¶”ê°€ ê°€ëŠ¥)
        if it.title in seen:
            continue
        seen.add(it.title)
        deduped.append(it)

    return deduped


def save_naver_ranking_to_db(items: List[NaverRankingNewsItem]) -> int:
    """
    íŒŒì‹±ëœ ë­í‚¹ë‰´ìŠ¤ë¥¼ PostgreSQLì— ì €ì¥.
    1) rank == 1ë§Œ ëŒ€ìƒìœ¼ë¡œ í•„í„°
    2) ì œëª© ê¸°ì¤€ìœ¼ë¡œ in-memory ì¤‘ë³µ ì œê±°
    3) categoryê°€ ë¹„ì–´ ìˆëŠ” í•­ëª©ë“¤ì— ëŒ€í•´ GPTë¡œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    4) DB ì €ì¥
    """
    if not items:
        return 0

    # ğŸ”¹ 1ìœ„ ê¸°ì‚¬ë§Œ ë‚¨ê¸°ê¸°
    items = [it for it in items if it.rank == 1]
    if not items:
        return 0

    # 2) ì œëª© ê¸°ì¤€ dedup
    items = _dedup_by_title(items)

    # 3) GPTë¡œ ì¹´í…Œê³ ë¦¬ ì±„ìš°ê¸° (category == None ì´ë‚˜ ë¹ˆ ê°’ë§Œ ëŒ€ìƒìœ¼ë¡œ)
    idx_list: list[int] = []
    titles_for_gpt: list[str] = []

    for idx, it in enumerate(items):
        if not it.category:  # None ë˜ëŠ” ë¹ˆ ë¬¸ìì—´
            idx_list.append(idx)
            titles_for_gpt.append(it.title)

    if titles_for_gpt:
        cats = categorize_news_titles_by_gpt(titles_for_gpt)
        for idx, cat in zip(idx_list, cats):
            items[idx].category = cat

    # 4) DB ì €ì¥ (ì—¬ê¸°ì„œë„ í•œ ë²ˆ ë” rank == 1ë§Œ ì €ì¥)
    payload = [
        {
            "press": it.press,
            "category": it.category,
            "rank": it.rank,
            "title": it.title,
            "link": it.link,
        }
        for it in items
        if it.rank == 1
    ]

    if not payload:
        return 0

    return save_naver_ranking_news(payload)


def collect_and_save_naver_ranking() -> List[NaverRankingNewsItem]:
    """
    1) HTML ê°€ì ¸ì˜¤ê³ 
    2) íŒŒì‹±í•´ì„œ
    3) rank 1ë§Œ í•„í„° + ì œëª© ê¸°ì¤€ ì¤‘ë³µ ì œê±° í›„ DBì— ì €ì¥
    4) ìµœì¢… ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    """
    html = fetch_naver_ranking_html()
    items = parse_naver_ranking(html)
    save_naver_ranking_to_db(items)
    # ë°˜í™˜ë„ rank 1 ê¸°ì¤€ìœ¼ë¡œ
    return [it for it in items if it.rank == 1]
